{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Tavola 8.6  - Abbonamenti alla radio e alla televisione italiana – Anni 1936-2014 ",
   "id": "2737362e541997dd"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-19T15:37:48.273064Z",
     "start_time": "2025-06-19T15:37:48.267159Z"
    }
   },
   "source": [
    "import sqlite3\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import plotly.express as px\n",
    "import sqlite3 as db"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Qui vengono caricati i path della cartella dedicata ai Datasets e del percorso specifico della serie Istat",
   "id": "3a79b0b945e10b06"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T15:37:58.839467Z",
     "start_time": "2025-06-19T15:37:58.832868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_dir = os.path.join(os.getcwd(), 'Datasets')\n",
    "df_path = (os.path.join(df_dir, 'Tavola_8.6.xlsx'))"
   ],
   "id": "d38dbf9a8826690a",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "La struttura della tabella non è pulita, dunque si è scelto di saltare le prime cinque righe (contenenti un'intestazione dell'Istat) e la sesta, in quanto quest'ultima è aggregata a quella successiva per la riga di intestazione della tabella. Inoltre saltiamo le ultime righe contenente solo una legenda.",
   "id": "8b4bd9e75602b047"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T15:38:48.666997Z",
     "start_time": "2025-06-19T15:38:48.555241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df1 = pd.read_excel(df_path, sheet_name='Tavola 8.6', skiprows=6, skipfooter=5) # sheet_name indica il foglio specifico da cui voglio creare il df dal file\n",
    "df2 = pd.read_excel(df_path, sheet_name='Tavola 8.6 (segue)', skiprows=6 , skipfooter=6) # il parametro skiprows viene speficicato per dedicere quante righe saltare al file della creazione del df"
   ],
   "id": "2a035e7c8a369202",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Program Files\\\\JetBrains\\\\PyCharm 2024.1.4\\\\jbr\\\\bin\\\\Datasets\\\\Tavola_8.6.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m df1 = \u001B[43mpd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread_excel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msheet_name\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mTavola 8.6\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskiprows\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m6\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskipfooter\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m5\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# sheet_name indica il foglio specifico da cui voglio creare il df dal file\u001B[39;00m\n\u001B[32m      2\u001B[39m df2 = pd.read_excel(df_path, sheet_name=\u001B[33m'\u001B[39m\u001B[33mTavola 8.6 (segue)\u001B[39m\u001B[33m'\u001B[39m, skiprows=\u001B[32m6\u001B[39m , skipfooter=\u001B[32m6\u001B[39m) \u001B[38;5;66;03m# il parametro skiprows viene speficicato per dedicere quante righe saltare al file della creazione del df\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\PycharmProjects\\AntiVirusPrj\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001B[39m, in \u001B[36mread_excel\u001B[39m\u001B[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001B[39m\n\u001B[32m    493\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(io, ExcelFile):\n\u001B[32m    494\u001B[39m     should_close = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m495\u001B[39m     io = \u001B[43mExcelFile\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    496\u001B[39m \u001B[43m        \u001B[49m\u001B[43mio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    497\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    498\u001B[39m \u001B[43m        \u001B[49m\u001B[43mengine\u001B[49m\u001B[43m=\u001B[49m\u001B[43mengine\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    499\u001B[39m \u001B[43m        \u001B[49m\u001B[43mengine_kwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mengine_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    500\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    501\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m engine \u001B[38;5;129;01mand\u001B[39;00m engine != io.engine:\n\u001B[32m    502\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    503\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mEngine should not be specified when passing \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    504\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33man ExcelFile - ExcelFile already has the engine set\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    505\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\PycharmProjects\\AntiVirusPrj\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001B[39m, in \u001B[36mExcelFile.__init__\u001B[39m\u001B[34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001B[39m\n\u001B[32m   1548\u001B[39m     ext = \u001B[33m\"\u001B[39m\u001B[33mxls\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1549\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1550\u001B[39m     ext = \u001B[43minspect_excel_format\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1551\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcontent_or_path\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstorage_options\u001B[49m\n\u001B[32m   1552\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1553\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m ext \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   1554\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   1555\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mExcel file format cannot be determined, you must specify \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1556\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33man engine manually.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1557\u001B[39m         )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\PycharmProjects\\AntiVirusPrj\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1402\u001B[39m, in \u001B[36minspect_excel_format\u001B[39m\u001B[34m(content_or_path, storage_options)\u001B[39m\n\u001B[32m   1399\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(content_or_path, \u001B[38;5;28mbytes\u001B[39m):\n\u001B[32m   1400\u001B[39m     content_or_path = BytesIO(content_or_path)\n\u001B[32m-> \u001B[39m\u001B[32m1402\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1403\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcontent_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrb\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_text\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[32m   1404\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m handle:\n\u001B[32m   1405\u001B[39m     stream = handle.handle\n\u001B[32m   1406\u001B[39m     stream.seek(\u001B[32m0\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\PycharmProjects\\AntiVirusPrj\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:882\u001B[39m, in \u001B[36mget_handle\u001B[39m\u001B[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[39m\n\u001B[32m    873\u001B[39m         handle = \u001B[38;5;28mopen\u001B[39m(\n\u001B[32m    874\u001B[39m             handle,\n\u001B[32m    875\u001B[39m             ioargs.mode,\n\u001B[32m   (...)\u001B[39m\u001B[32m    878\u001B[39m             newline=\u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    879\u001B[39m         )\n\u001B[32m    880\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    881\u001B[39m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m882\u001B[39m         handle = \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mioargs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    883\u001B[39m     handles.append(handle)\n\u001B[32m    885\u001B[39m \u001B[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001B[39;00m\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: 'C:\\\\Program Files\\\\JetBrains\\\\PyCharm 2024.1.4\\\\jbr\\\\bin\\\\Datasets\\\\Tavola_8.6.xlsx'"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df1",
   "id": "702538a2449abdb5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df2",
   "id": "52926374bd4e4cb0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Notiamo che l'aggregazione delle righe sul file excel sta generando confusione per pandas, dunque rinominiamo manualmente l'header della tabella. Inoltre notiamo che la riga 0 è vuota, quindi possiamo eliminarla. La stessa cosa vale per la terza colonna, che è vuota e non rappresenta nulla (su entrambi gli sheet).",
   "id": "cf3202f59d09d6cc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "columns = [\n",
    "    \"Anno\", \n",
    "    \"Radio (a)\",\n",
    "    \"TV - Uso privato\", \n",
    "    \"TV - Speciali (b)\", \n",
    "    \"TV - Totale\", \n",
    "    \"Abbonamenti TV per 1000 abitanti\",\n",
    "    \"Abbonamenti TV per 100 famiglie\"\n",
    "]"
   ],
   "id": "3c2da07b080f437c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df1.drop('Unnamed: 2', axis=1, inplace=True) # axis = 1 in questo caso fa in modo di eliminare una colonna, inplace settato a true fa operare sullo stesso df\n",
    "df2.drop('Unnamed: 2', axis=1, inplace=True) \n",
    "df1.drop(0, inplace=True)\n",
    "df2.drop(0, inplace=True)\n",
    "\n",
    "df1.columns=columns\n",
    "df2.columns=columns"
   ],
   "id": "68eceb90fe147ea8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Notiamo che una parte degli anni sembra essere un float, quindi specifichiamo il valore a int",
   "id": "239fafc52b8d1aa5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T15:33:52.133678Z",
     "start_time": "2025-06-19T15:33:52.132679Z"
    }
   },
   "cell_type": "code",
   "source": "df1[\"Anno\"] = df1[\"Anno\"].astype(int)",
   "id": "b5e862c47d9631dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Concateniamo ora i due dataframe derivanti dai due fogli del file",
   "id": "ccbc42925c96598a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T15:33:52.134679Z",
     "start_time": "2025-06-19T15:33:52.133678Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.concat([df1, df2], ignore_index=True) # dal momento che l'indice riparte da 0 nel secondo foglio, settiamo ignore_index a true",
   "id": "2d2bec185ab9923",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T15:33:52.135678Z",
     "start_time": "2025-06-19T15:33:52.135678Z"
    }
   },
   "cell_type": "code",
   "source": "df",
   "id": "5e305c5b56aae87a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "La struttura del df è parzialmente pulita, resta solo da rendere come index la colonna anno e pulire l'anno 2002",
   "id": "3e45cd5eaeb7ec57"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.loc[df[\"Anno\"] == \"2002 (c)\", \"Anno\"] = 2002 # il primo è l'indice della riga, il secondo della colonna",
   "id": "7d35e1e38aa9d423",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.set_index(\"Anno\", inplace=True)",
   "id": "7e7e68ea0fee6b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Analizzando la colonna degli ascolti radio si nota che molti valori sono sporchi (rappresentati con \"...\"). Per pulire il df, rimpiazziamo questi valori con NaN.",
   "id": "9719b68c90d2fa91"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.replace(\"….\", pd.NA, inplace=True)",
   "id": "c1ea396d886424d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ciononostante la colonna non è ancora numerica, quindi dobbiamo convertirla",
   "id": "411ba9dbe5d890ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df[\"Radio (a)\"] = pd.to_numeric(df[\"Radio (a)\"], errors=\"coerce\")",
   "id": "c0fabae1788b4137",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ammettiamo di voler lavorare solo sugli ascolti radio (li prendiamo dal 1936 al 1989 in quanto in seguito i dati non sono disponibili)",
   "id": "5e5316e618eda59d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T15:33:52.142680Z",
     "start_time": "2025-06-19T15:33:52.141680Z"
    }
   },
   "cell_type": "code",
   "source": "df_radio = df.loc[(df.index >= 1936) & (df.index <= 1989), ['Radio (a)']].copy()\n",
   "id": "ccacec30e63e630c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Nota bene, questo codice invece non avrebbe funzionato in quanto \"Anno\" è un index\n",
    "\n",
    "df_radio = df.loc[\n",
    "    (df[\"Anno\"] >= 1936) & (df[\"Anno\"] <= 1989),  \n",
    "    [\"Anno\", \"Radio (a)\"]\n",
    "].copy()"
   ],
   "id": "bcb70d0a1a01453e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Possiamo provare ad interpolare i dati mancanti (dal momento che ce ne sono pochi)",
   "id": "3d1b8b0cf5bfd47a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T15:33:52.144686Z",
     "start_time": "2025-06-19T15:33:52.144686Z"
    }
   },
   "cell_type": "code",
   "source": "df_radio[\"Radio (a)\"] = df_radio[\"Radio (a)\"].interpolate(method=\"linear\")",
   "id": "b8e6b129fa69554a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_radio.plot(kind='line') ",
   "id": "7491884a3f0658b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Con plotly express",
   "id": "bbe4305463e357c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = px.line(df_radio, x=df_radio.index, y=\"Radio (a)\")\n",
    "fig.show()"
   ],
   "id": "54ca6a0ca0d71e77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Proviamo a creare un database per inserirci i dati dal dataframe. Creiamo inizialmente una cartella Database.",
   "id": "633db65f5936d387"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "db_path = (os.path.join(os.getcwd(), 'Database'))",
   "id": "fc4cae98850d628f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dopodichè creiamo una connessione al database, se non esiste il file (in questo caso 'database.db') viene creato.",
   "id": "9839a74543d0e8d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "conn = db.connect(os.path.join(db_path, 'database.db'))",
   "id": "34f40b683d828d72",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creiamo la tabella ascolti_radio sul db, specificandone il name e chiamando il metodo .to_sql sul df",
   "id": "af9d96b97156eb0c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creiamo il cursore",
   "id": "7313750eb443bd7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cursor = conn.cursor()",
   "id": "1e66138c1739b40f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cursor.execute(\"DROP TABLE IF EXISTS ascolti_radio\")",
   "id": "92572725dc7d3268",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a45a6185f5331c77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "c8d963f2bbb3389b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cursor.execute(\"\"\"CREATE TABLE IF NOT EXISTS ascolti_radio (\n",
    "Anno INTEGER PRIMARY KEY,\n",
    "\"Radio (a)\" DOUBLE,\n",
    "\"TV - Uso privato\" DOUBLE\n",
    ")\"\"\")"
   ],
   "id": "ca8933d7b4912b17",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_radio.to_sql(name='ascolti_radio', con=conn, if_exists='append')",
   "id": "e3e873672d50f8b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Eseguiamo la query",
   "id": "3c03f88d0e5d5054"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cursor.execute(\"SELECT * FROM ascolti_radio\")",
   "id": "253a071790bb4a7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Salviamone i risultati nella variabile rows e dopodichè stampiamo i risultati",
   "id": "fd3d30ff88e73374"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "rows = cursor.fetchall()",
   "id": "37647171ee356a97",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T15:33:52.162679Z",
     "start_time": "2025-06-19T15:33:52.161681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for row in rows:\n",
    "    print(row)"
   ],
   "id": "11f995eabe820646",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Fare riferimento al modulo main per la creazione delle API",
   "id": "c1dfeecd0a7616ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Tornando alla dataviz, cerchiamo ora di concatenare (anche se si poteva fare solo un sottodf di quello iniziale) anche gli ascolti TV",
   "id": "f29fc848cff9c838"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Puliamo inizialmente gli ascolti TV privati",
   "id": "d042f4f289e687aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-06-19T15:33:52.163679Z"
    }
   },
   "cell_type": "code",
   "source": "df.replace(\"-\", pd.NA, inplace=True)",
   "id": "c8b9f03fb39cff64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df[\"TV - Uso privato\"] = pd.to_numeric(df[\"TV - Uso privato\"], errors=\"coerce\")",
   "id": "91f11f551c605591",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-19T15:33:52.165678Z",
     "start_time": "2025-06-19T15:33:52.165678Z"
    }
   },
   "cell_type": "code",
   "source": "df_tv_priv = df.loc[(df.index >= 1936) & (df.index <= 1989), ['TV - Uso privato']].copy()",
   "id": "89aa88ed07c7541a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-06-19T15:33:52.166679Z"
    }
   },
   "cell_type": "code",
   "source": "df_tv_priv",
   "id": "d6bd4bbcd46af259",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dobbiamo affiancare le colonne, dunque utilizziamo axis=1",
   "id": "6435f4cf7a0f9f71"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_radio_tv_priv = pd.concat([df_radio, df_tv_priv], axis=1)",
   "id": "851fb356873689c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_radio_tv_priv",
   "id": "3987970a1708a039",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Svuotiamo la tabella (nota, non esiste truncate)",
   "id": "e56066239353ab72"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "cursor.execute(\"DELETE FROM ascolti_radio\")",
   "id": "d7e9d38fc03aab58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_radio_tv_priv.to_sql(name='ascolti_radio', con=conn, if_exists='append')",
   "id": "bb50849c9ab2ef41",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creiamo ora una nuova figura passando le due serie sull'asse Y",
   "id": "1dc8c4451ea06615"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig2 = px.line(df_radio_tv_priv, x=df_radio_tv_priv.index, y=[\"Radio (a)\", \"TV - Uso privato\"])\n",
    "fig2.show()\n"
   ],
   "id": "9c4e8b073468049d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_radio_tv_priv.to_csv(os.path.join(os.getcwd(), 'Outputs', 'ascolti_radio_tv_priv.csv'))",
   "id": "79f1dcf9bbc87c4c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6ba2839bc3ef1eb5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
